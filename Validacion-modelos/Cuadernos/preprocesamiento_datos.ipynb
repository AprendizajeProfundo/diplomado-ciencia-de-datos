{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45dcfa44-686e-479a-9507-cd18e3f721ef",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "<figure> \n",
    "<img src=\"../Imagenes/logo-final-ap.png\"  width=\"80\" height=\"80\" align=\"left\"/> \n",
    "</figure>\n",
    "\n",
    "# <span style=\"color:blue\"><left>Aprendizaje Profundo</left></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d6f0ea-63ec-4a6b-b3bc-a5985d46f54c",
   "metadata": {},
   "source": [
    "# <span style=\"color:red\"><center>Pre-procesamiento de datos</center></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c888c1a-e2b2-49f2-895f-0afb20352f28",
   "metadata": {},
   "source": [
    "##   <span style=\"color:blue\">Profesores</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338c827e-23e4-447e-970f-fc1537c89374",
   "metadata": {},
   "source": [
    "1. Alvaro Mauricio Montenegro Díaz, ammontenegrod@unal.edu.co\n",
    "2. Daniel Mauricio Montenegro Reyes, dextronomo@gmail.com \n",
    "3. Campo Elías Pardo Turriago, cepardot@unal.edu.co \n",
    "4. Camilo José Torres Jiménez, MSc, cjtorresj@unal.edu.co"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56afc3f5-e38e-4fd2-9051-2529490e0a4f",
   "metadata": {},
   "source": [
    "##   <span style=\"color:blue\">Estudiantes auxiliares</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74668380-53aa-434f-b47e-a8f2d4ee5178",
   "metadata": {},
   "source": [
    "##   <span style=\"color:blue\">Asesora Medios y Marketing digital</span>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89933aaf-7a7d-45ac-ac70-ec292666aa87",
   "metadata": {},
   "source": [
    "1. Maria del Pilar Montenegro, pmontenegro88@gmail.com "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d767c1b-f397-4d35-b5df-4047a01493c2",
   "metadata": {},
   "source": [
    "##   <span style=\"color:blue\">Introducción al preprocesamiento de datos con scikit-learn</span>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21314ebe-95e4-4e4e-a099-f755a769a70c",
   "metadata": {},
   "source": [
    "El preprocesamiento de datos es un paso fundamental en el análisis de datos y el aprendizaje automático. Para abordar este importante proceso, scikit-learn, una de las bibliotecas de aprendizaje automático más utilizadas, ofrece un conjunto poderoso de herramientas y transformadores en su módulo `sklearn.preprocessing`. Este paquete está diseñado para ayudar a los científicos de datos y a los ingenieros de aprendizaje automático a preparar sus datos de manera efectiva para aplicar algoritmos de aprendizaje y modelado.\n",
    "\n",
    "En el mundo real, los conjuntos de datos suelen ser desordenados, ruidosos y contener una variedad de características. El paquete `sklearn.preprocessing` aborda estos desafíos al proporcionar una serie de métodos y transformadores que permiten:\n",
    "\n",
    "1. **Limpieza de Datos:** Identificar y tratar valores faltantes, valores atípicos y datos inconsistentes que pueden afectar negativamente el rendimiento de los modelos.\n",
    "\n",
    "2. **Normalización y Escalado:** Asegurar que las características tengan la misma escala, lo que es crucial para algoritmos sensibles a la magnitud de las características, como las máquinas de soporte vectorial (SVM) y la regresión logística.\n",
    "\n",
    "3. **Codificación de Variables Categóricas:** Convertir variables categóricas en representaciones numéricas adecuadas para el aprendizaje automático.\n",
    "\n",
    "4. **Reducción de Dimensionalidad:** Reducir la complejidad de los datos al conservar solo las características más informativas, lo que puede mejorar la eficiencia del modelo y evitar problemas de sobreajuste.\n",
    "\n",
    "5. **Generación de Características:** Crear nuevas características a partir de las existentes para capturar información adicional y mejorar la capacidad predictiva de los modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6294d2-3cab-409a-9360-3bdffe40c353",
   "metadata": {},
   "source": [
    "El material del cuaderno está basado en la documentación oficial de scikit-learn [https://scikit-learn.org/stable/modules/preprocessing.html#preprocessing]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf7b2b9-d97f-4939-9592-1394dab48c13",
   "metadata": {},
   "source": [
    "El paquete `sklearn.preprocessing` proporciona varias funciones de utilidad comunes y clases de transformadores para convertir vectores de características en bruto en una representación más adecuada para los estimadores posteriores.\n",
    "\n",
    "En general, los algoritmos de aprendizaje se benefician de la estandarización del conjunto de datos. Si hay valores atípicos presentes en el conjunto, es más apropiado utilizar escaladores o transformadores robustos. Los comportamientos de los diferentes escaladores, transformadores y normalizadores en un conjunto de datos que contiene valores atípicos marginales se destacan en \"Comparar el efecto de diferentes escaladores en datos con valores atípicos\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1fc6b33-b0df-4df1-bf91-c2497b16f6d9",
   "metadata": {},
   "source": [
    "##   <span style=\"color:blue\">Estandarización, o eliminación de la media y escalado de la varianza.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b756fbe7-6fa6-4920-ae86-20869e149cf8",
   "metadata": {},
   "source": [
    "La estandarización de conjuntos de datos es un requisito común para muchos estimadores de aprendizaje automático implementados en scikit-learn; pueden comportarse de manera deficiente si las características individuales no se parecen más o menos a datos distribuidos normalmente estándar: Gaussianos con media cero y varianza unitaria.\n",
    "\n",
    "En la práctica, a menudo ignoramos la forma de la distribución y simplemente transformamos los datos para centrarlos, eliminando el valor medio de cada característica, y luego los escalamos dividiendo las características no constantes por su desviación estándar.\n",
    "\n",
    "Por ejemplo, muchos elementos utilizados en la función objetivo de un algoritmo de aprendizaje (como el kernel RBF de las Máquinas de Soporte Vectorial o los regularizadores l1 y l2 de modelos lineales) pueden asumir que todas las características están centradas alrededor de cero o tienen varianza en el mismo orden de magnitud. Si una característica tiene una varianza que es órdenes de magnitud mayor que otras, puede dominar la función objetivo y hacer que el estimador no pueda aprender correctamente de otras características como se esperaba.\n",
    "\n",
    "El módulo de preprocesamiento proporciona la clase de utilidad StandardScaler, que es una forma rápida y sencilla de realizar la siguiente operación en un conjunto de datos similar a una matriz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bacdccdd-1b92-4081-bcba-d7daf606f3d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StandardScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importa las bibliotecas necesarias\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "# Crea una matriz de ejemplo\n",
    "X_train = np.array([[1., -1., 2.],\n",
    "                    [2., 0., 0.],\n",
    "                    [0., 1., -1.]])\n",
    "\n",
    "# Inicializa el objeto StandardScaler y ajusta (fit) los datos\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "\n",
    "# Verifica el objeto scaler\n",
    "scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c328ed2-848f-4a98-bcbc-3ea7bc9b024a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.        , 0.33333333])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Media de las características\n",
    "scaler.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7795485d-8cd2-446d-a9a4-6dee535908b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.81649658, 0.81649658, 1.24721913])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Escala de las características\n",
    "scaler.scale_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39ebb74e-9830-4824-b7f4-67748e802950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , -1.22474487,  1.33630621],\n",
       "       [ 1.22474487,  0.        , -0.26726124],\n",
       "       [-1.22474487,  1.22474487, -1.06904497]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transforma los datos utilizando el scaler\n",
    "X_scaled = scaler.transform(X_train)\n",
    "X_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4f1c48-6883-4e34-90b5-8ecd8fdee7fb",
   "metadata": {},
   "source": [
    "Los datos escalados tienen una media cero y una varianza unitaria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69a255d9-cc9b-470d-a72c-9a6aff0198eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calcular la media de las características escaladas a lo largo del eje 0 (columnas)\n",
    "mean_scaled = X_scaled.mean(axis=0)\n",
    "mean_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87c229ea-4a56-49b4-9947-d48d291c6cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1.])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calcular la desviación estándar de las características escaladas a lo largo del eje 0 (columnas)\n",
    "std_scaled = X_scaled.std(axis=0)\n",
    "std_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8f890e-fdbd-43e0-b7cc-fe959d3462c8",
   "metadata": {},
   "source": [
    "Esta clase implementa la API de transformadores para calcular la media y la desviación estándar en un conjunto de entrenamiento, de modo que sea posible volver a aplicar la misma transformación más tarde en el conjunto de pruebas. Por lo tanto, esta clase es adecuada para su uso en las primeras etapas de un Pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67136e12-3c35-49c7-bda1-26532014395c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;logisticregression&#x27;, LogisticRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;logisticregression&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('logisticregression', LogisticRegression())])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importa las bibliotecas necesarias\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Genera datos de clasificación sintéticos\n",
    "X, y = make_classification(random_state=42)\n",
    "\n",
    "# Divide los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Crea un pipeline que incluye la estandarización y un modelo de regresión logística\n",
    "pipe = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "\n",
    "# Ajusta el pipeline al conjunto de entrenamiento (aplicando la estandarización)\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# Muestra el pipeline\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bf4819f-82d0-45c7-bec5-602bbc1006ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evalúa el modelo en el conjunto de prueba (aplicando la estandarización)\n",
    "score = pipe.score(X_test, y_test)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15eed04-059a-4817-adf7-601617f2a4ba",
   "metadata": {},
   "source": [
    "Es posible desactivar la centralización o el escalado pasando with_mean=False o with_std=False al constructor de StandardScaler."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af2aa2f-b52b-4241-bd79-91ec378c0474",
   "metadata": {},
   "source": [
    "##   <span style=\"color:blue\">Escalar características a un rango</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1378576-f657-4984-ad74-f12e539f6ed2",
   "metadata": {},
   "source": [
    "Una alternativa de estandarización es escalar las características para que se encuentren dentro de un valor mínimo y máximo dado, a menudo entre cero y uno, o de manera que el valor absoluto máximo de cada característica se escale a tamaño unitario. Esto se puede lograr utilizando MinMaxScaler o MaxAbsScaler, respectivamente.\n",
    "\n",
    "La motivación para utilizar este tipo de escalado incluye la robustez frente a desviaciones estándar muy pequeñas de las características y la preservación de entradas en cero en datos dispersos (sparse data).\n",
    "\n",
    "Aquí tienes un ejemplo para escalar una matriz de datos de juguete al rango [0, 1]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73f6bae8-c851-4f79-82cd-237c2ab8df79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5       , 0.        , 1.        ],\n",
       "       [1.        , 0.5       , 0.33333333],\n",
       "       [0.        , 1.        , 0.        ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importa las bibliotecas necesarias\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "# Crea una matriz de ejemplo\n",
    "X_train = np.array([[1., -1., 2.],\n",
    "                    [2., 0., 0.],\n",
    "                    [0., 1., -1.]])\n",
    "\n",
    "# Inicializa el objeto MinMaxScaler\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "# Aplica la transformación Min-Max a los datos de entrenamiento\n",
    "X_train_minmax = min_max_scaler.fit_transform(X_train)\n",
    "\n",
    "# Muestra la matriz de datos después de la transformación Min-Max\n",
    "X_train_minmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfd38dd-c84a-43d7-9e02-ef69c173fdcf",
   "metadata": {},
   "source": [
    "La misma instancia del transformador luego se puede aplicar a algunos nuevos datos de prueba que no se vieron durante la llamada al método \"fit\": las mismas operaciones de escalado y desplazamiento se aplicarán para que sean coherentes con la transformación realizada en los datos de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "672ea895-4c05-490e-806a-1d603a23de33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.5       ,  0.        ,  1.66666667]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importa las bibliotecas necesarias\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Crea un conjunto de prueba con características\n",
    "X_test = np.array([[-3., -1.,  4.]])\n",
    "\n",
    "# Utiliza el transformador MinMaxScaler previamente creado\n",
    "X_test_minmax = min_max_scaler.transform(X_test)\n",
    "\n",
    "# Muestra el conjunto de prueba escalado utilizando MinMaxScaler\n",
    "X_test_minmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ef4e87-8e28-4759-8f24-bb6d7856c7ac",
   "metadata": {},
   "source": [
    "Es posible inspeccionar los atributos del escalador para obtener información sobre la naturaleza exacta de la transformación aprendida en los datos de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76075e83-7cd3-4fb4-bfe0-db74b8f68c90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5       , 0.5       , 0.33333333])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostrar la escala y el mínimo después de aplicar Min-Max Scaling\n",
    "min_max_scaler.scale_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e03f8b9-55cc-469c-a058-8c5f76f8a723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.5       , 0.33333333])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostrar el mínimo después de aplicar Min-Max Scaling\n",
    "min_max_scaler.min_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52c1b7c-9749-4bd4-a663-2a7910d98f07",
   "metadata": {},
   "source": [
    "Si se proporciona un rango de características explícito (feature_range=(min, max)) a MinMaxScaler, la fórmula completa es la siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce2332c-41f9-4716-8e72-0d62dfadd640",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_std = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))\n",
    "\n",
    "X_scaled = X_std * (max - min) + min"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07da4d6d-5e8e-4cc9-a7be-2df55cd8e60a",
   "metadata": {},
   "source": [
    "MaxAbsScaler funciona de manera muy similar, pero escala de tal manera que los datos de entrenamiento se encuentran dentro del rango [-1, 1] dividiendo por el valor máximo más grande en cada característica. Está diseñado para datos que ya están centrados en cero o para datos dispersos.\n",
    "\n",
    "Aquí tienes cómo usar los datos de juguete del ejemplo anterior con este escalador:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6282a21b-4712-4bf0-85ca-0e79c5837ae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.5, -1. ,  1. ],\n",
       "       [ 1. ,  0. ,  0. ],\n",
       "       [ 0. ,  1. , -0.5]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importa las bibliotecas necesarias\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Datos de entrenamiento\n",
    "X_train = np.array([[ 1., -1.,  2.],\n",
    "                    [ 2.,  0.,  0.],\n",
    "                    [ 0.,  1., -1.]])\n",
    "\n",
    "# Inicializa el transformador MaxAbsScaler\n",
    "max_abs_scaler = preprocessing.MaxAbsScaler()\n",
    "\n",
    "# Aplica MaxAbsScaler al conjunto de entrenamiento\n",
    "X_train_maxabs = max_abs_scaler.fit_transform(X_train)\n",
    "\n",
    "# Muestra el conjunto de entrenamiento escalado con MaxAbsScaler\n",
    "X_train_maxabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3aa4c214-4279-43f7-8911-7280fe23fa02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.5, -1. ,  2. ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Datos de prueba\n",
    "X_test = np.array([[ -3., -1.,  4.]])\n",
    "\n",
    "# Aplica MaxAbsScaler al conjunto de prueba\n",
    "X_test_maxabs = max_abs_scaler.transform(X_test)\n",
    "\n",
    "# Muestra el conjunto de prueba escalado con MaxAbsScaler\n",
    "X_test_maxabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20bc1fd7-c230-4db0-ba9d-cb2f27024feb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 1., 2.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Muestra las escalas utilizadas por MaxAbsScaler\n",
    "max_abs_scaler.scale_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94becc5-f276-4b9e-8979-8b067b6d1027",
   "metadata": {},
   "source": [
    "##   <span style=\"color:blue\">Escalar datos dispersos.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9487fc2c-01a4-4e38-a6d3-bc7d1726ad7a",
   "metadata": {},
   "source": [
    "Centrar datos dispersos destruiría la estructura de dispersión en los datos, por lo que rara vez es algo sensato hacer. Sin embargo, puede tener sentido escalar entradas dispersas, especialmente si las características están en diferentes escalas.\n",
    "\n",
    "MaxAbsScaler fue diseñado específicamente para escalar datos dispersos y es la forma recomendada de hacerlo. Sin embargo, StandardScaler puede aceptar matrices dispersas de scipy como entrada, siempre y cuando se pase explícitamente with_mean=False al constructor. De lo contrario, se generará un ValueError, ya que centrar silenciosamente rompería la dispersión y, a menudo, causaría la interrupción de la ejecución al asignar inadvertidamente cantidades excesivas de memoria. RobustScaler no se puede ajustar a entradas dispersas, pero puedes utilizar el método de transformación en entradas dispersas.\n",
    "\n",
    "Ten en cuenta que los escaladores aceptan tanto el formato de Compressed Sparse Rows como el de Compressed Sparse Columns (consulta scipy.sparse.csr_matrix y scipy.sparse.csc_matrix). Cualquier otra entrada dispersa se convertirá en la representación de Compressed Sparse Rows. Para evitar copias innecesarias de memoria, se recomienda elegir la representación CSR o CSC en la entrada original.\n",
    "\n",
    "Por último, si se espera que los datos centralizados sean lo suficientemente pequeños, otra opción es convertir explícitamente la entrada en una matriz utilizando el método toarray de las matrices dispersas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c00ca6c-d4a6-4fda-ab3f-39fa4c10761c",
   "metadata": {},
   "source": [
    "##   <span style=\"color:blue\">Escalar datos con valores atípicos.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335a83d9-5fbd-474e-904e-bff363fb54e0",
   "metadata": {},
   "source": [
    "Si tus datos contienen muchos valores atípicos, escalarlos utilizando la media y la varianza de los datos probablemente no funcionará muy bien. En estos casos, puedes utilizar RobustScaler como un reemplazo directo. Utiliza estimaciones más robustas para el centro y el rango de tus datos.\n",
    "\n",
    "Referencias:\n",
    "\n",
    "Una discusión más detallada sobre la importancia de centrar y escalar los datos está disponible en esta FAQ: ¿Debo normalizar/estandarizar/reescalar los datos? [http://www.faqs.org/faqs/ai-faq/neural-nets/part2/section-16.html]\n",
    "\n",
    "Escalar vs. Blanquear (Whitening)\n",
    "\n",
    "A veces, no es suficiente centrar y escalar las características de manera independiente, ya que un modelo posterior puede hacer suposiciones adicionales sobre la independencia lineal de las características.\n",
    "\n",
    "Para abordar este problema, puedes utilizar PCA con whiten=True para eliminar aún más la correlación lineal entre las características."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2669e1-d5a1-4529-8cae-78b6c8412c47",
   "metadata": {},
   "source": [
    "##   <span style=\"color:blue\">Centrar las matrices de kernel</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98660118-c9a9-4b26-9e00-6be14b2a60d2",
   "metadata": {},
   "source": [
    "Si tienes una matriz de kernel de un kernel $K$ que calcula un producto punto en un espacio de características (posiblemente implícito) definido por una función $\\phi(\\cdot)$, un KernelCenterer puede transformar la matriz de kernel para que contenga productos internos en el espacio de características definido por $\\phi(\\cdot)$ seguido de la eliminación de la media en ese espacio. En otras palabras, KernelCenterer calcula la matriz de Gram centrada asociada a un kernel semidefinido positivo $K$.\n",
    "\n",
    "Formulación matemática\n",
    "\n",
    "Podemos echar un vistazo a la formulación matemática ahora que tenemos la intuición. Sea $K$ una matriz de kernel de forma (n_samples, n_samples) calculada a partir de X, una matriz de datos de forma (n_samples, n_features), durante el paso de ajuste. $K$ está definida por:\n",
    "\n",
    "$$\n",
    "K(X, X) = \\phi(X) \\cdot \\phi(X)^{T}\n",
    "$$\n",
    "\n",
    "$\\phi(X)$ es una función que asigna X a un espacio de Hilbert. Un kernel centrado $\\tilde{K}$ se define como:\n",
    "\n",
    "$$\n",
    "\\tilde{K}(X, X) = \\tilde{\\phi}(X) \\cdot \\tilde{\\phi}(X)^{T}\n",
    "$$\n",
    "\n",
    "donde $\\tilde{\\phi}(X)$ resulta de centrar $\\phi(X)$ en el espacio de Hilbert.\n",
    "\n",
    "Así, uno podría calcular $\\tilde{K}$ mapeando $X$ utilizando la función $\\phi(\\cdot)$ y centrando los datos en este nuevo espacio. Sin embargo, los kernels a menudo se utilizan porque permiten algunos cálculos algebraicos que evitan calcular explícitamente este mapeo utilizando $\\phi(\\cdot)$. De hecho, uno puede centrar implícitamente como se muestra en el Apéndice B en [Scikit-Learn](https://scikit-learn.org/stable/modules/preprocessing.html#scholkopf1998):\n",
    "\n",
    "$$\n",
    "\\tilde{K} = K - 1_{\\text{n}_{samples}} K - K 1_{\\text{n}_{samples}} + 1_{\\text{n}_{samples}} K 1_{\\text{n}_{samples}}\n",
    "$$\n",
    "\n",
    "$1_{\\text{n}_{samples}}$ es una matriz de (n_samples, n_samples) donde todas las entradas son iguales a $\\frac{1}{\\text{n}_{samples}}$. En el paso de transformación, el kernel se convierte en $K_{test}(X, Y)$ definido como:\n",
    "\n",
    "$$\n",
    "K_{test}(X, Y) = \\phi(Y) \\cdot \\phi(X)^{T}\n",
    "$$\n",
    "\n",
    "$Y$ es el conjunto de pruebas de datos de forma (n_samples_test, n_features) y, por lo tanto, $K_{test}$ es de forma (n_samples_test, n_samples). En este caso, el centrado de $K_{test}$ se realiza como:\n",
    "\n",
    "$$\n",
    "\\tilde{K}_{test}(X, Y) = K_{test} - 1'_{\\text{n}_{samples}} K - K_{test} 1_{\\text{n}_{samples}} + 1'_{\\text{n}_{samples}} K 1_{\\text{n}_{samples}}\n",
    "$$\n",
    "\n",
    "$1'_{\\text{n}_{samples}}$ es una matriz de forma (n_samples_test, n_samples) donde todas las entradas son iguales a $\\frac{1}{\\text{n}_{samples}}$.\n",
    "\n",
    "Referencias\n",
    "- [Scikit-Learn](https://scikit-learn.org/stable/modules/preprocessing.html#scholkopf1998)\n",
    "- B. Schölkopf, A. Smola, and K.R. Müller, \"[MLpack - Kernel Principal Component Analysis](https://www.mlpack.org/papers/kpca.pdf).\" Neural computation 10.5 (1998): 1299-1319."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210b1305-ba67-49ec-b18c-6899e04d25a8",
   "metadata": {},
   "source": [
    "##   <span style=\"color:blue\">Tranformación no lineal</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0714347e-3442-4102-bf76-fd1e5aa1ed42",
   "metadata": {},
   "source": [
    "Dos tipos de transformaciones están disponibles: transformaciones de cuantiles y transformaciones de potencia. Tanto las transformaciones de cuantiles como las de potencia se basan en transformaciones monótonas de las características y, por lo tanto, preservan la clasificación de los valores a lo largo de cada característica.\n",
    "\n",
    "Las transformaciones de cuantiles colocan todas las características en la misma distribución deseada según la fórmula\n",
    "$G_{-1}(F(X_i))$ donde $F$ es la función de distribución acumulativa de la característica y $G_{-1}$ es la función de cuantiles de la distribución de salida deseada. Esta fórmula se basa en los dos siguientes hechos: (i) si $X$ es una variable aleatoria con una función de distribución acumulativa continua $F$, entonces $F(X)$ está uniformemente distribuido en [0, 1]; (ii) si $U$ es una variable aleatoria con una distribución uniforme en [0, 1], entonces $G^{-1}(U)$ tiene una distribución $G$.\n",
    "\n",
    "Al realizar una transformación de rango, una transformación de cuantiles suaviza las distribuciones inusuales y se ve menos influenciada por valores atípicos que los métodos de escalado. Sin embargo, distorsiona correlaciones y distancias dentro y entre características.\n",
    "\n",
    "Las transformaciones de potencia son una familia de transformaciones paramétricas que tienen como objetivo mapear los datos desde cualquier distribución hacia una distribución gaussiana lo más cercana posible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527ba1fc-ff8c-4601-ab5e-1325054c72ae",
   "metadata": {},
   "source": [
    "###   <span style=\"color:blue\">Mapeo a una distribución uniforme.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce5b001-7dfc-425d-bb59-c73a41005b8b",
   "metadata": {},
   "source": [
    "QuantileTransformer proporciona una transformación no paramétrica para mapear los datos a una distribución uniforme con valores entre 0 y 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "317ff108-93a7-4144-b83d-6c17e5e8fa3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anroj\\anaconda3\\envs\\Plotly\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:2627: UserWarning: n_quantiles (1000) is greater than the total number of samples (112). n_quantiles is set to n_samples.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([4.3, 5.1, 5.8, 6.5, 7.9])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importa las bibliotecas necesarias\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "# Carga el conjunto de datos de Iris y divide los datos en conjuntos de entrenamiento y prueba\n",
    "X, y = load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "# Aplica la transformación de cuantiles utilizando el QuantileTransformer\n",
    "quantile_transformer = preprocessing.QuantileTransformer(random_state=0)\n",
    "X_train_trans = quantile_transformer.fit_transform(X_train)\n",
    "X_test_trans = quantile_transformer.transform(X_test)\n",
    "\n",
    "# Calcula los percentiles de la primera característica del conjunto de entrenamiento\n",
    "percentiles = np.percentile(X_train[:, 0], [0, 25, 50, 75, 100])\n",
    "percentiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57639bbb-ba1d-4058-ae9c-79f94bcdeea9",
   "metadata": {},
   "source": [
    "Este atributo corresponde a la longitud del sépalo en centímetros. Una vez aplicada la transformación de cuantiles, estos puntos de referencia se acercan estrechamente a los percentiles previamente definidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85b2ec1b-0b32-451d-af27-84cfd27d0f28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.23873874, 0.50900901, 0.74324324, 1.        ])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(X_train_trans[:, 0], [0, 25, 50, 75, 100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7ddc46-bb66-41a4-b376-8e0a001b9d61",
   "metadata": {},
   "source": [
    "Esto se puede confirmar en un conjunto de prueba independiente con observaciones similares:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55e1c812-a328-4a88-8ba6-302160db73db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.4  , 5.125, 5.75 , 6.175, 7.3  ])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(X_test[:, 0], [0, 25, 50, 75, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bebb6e6c-3df1-483f-a74d-ffd39ef15da4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01351351, 0.25      , 0.47747748, 0.60472973, 0.94144144])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(X_test_trans[:, 0], [0, 25, 50, 75, 100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034972e2-a89c-4aa0-9dc7-3567ee0325ad",
   "metadata": {},
   "source": [
    "###   <span style=\"color:blue\">Mapeo a una distribución gausiana.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3e511e-293a-4b1b-b430-9e2e3b2ed704",
   "metadata": {},
   "source": [
    "Por supuesto, aquí está el mismo texto con los símbolos \\[ reemplazados por $$:\n",
    "\n",
    "En muchos escenarios de modelado, la normalidad de las características en un conjunto de datos es deseable. Las transformaciones de potencia son una familia de transformaciones paramétricas y monótonas que tienen como objetivo mapear los datos desde cualquier distribución lo más cerca posible de una distribución gaussiana para estabilizar la varianza y minimizar la asimetría.\n",
    "\n",
    "PowerTransformer proporciona actualmente dos de estas transformaciones de potencia, la transformación Yeo-Johnson y la transformación Box-Cox.\n",
    "\n",
    "La transformación Yeo-Johnson se define como:\n",
    "\n",
    "$$\n",
    "x_i^{(\\lambda)} =\n",
    "\\begin{cases}\n",
    " [(x_i + 1)^\\lambda - 1] / \\lambda & \\text{si } \\lambda \\neq 0, x_i \\geq 0, \\\\[8pt]\n",
    "\\ln{(x_i + 1)} & \\text{si } \\lambda = 0, x_i \\geq 0 \\\\[8pt]\n",
    "-[(-x_i + 1)^{2 - \\lambda} - 1] / (2 - \\lambda) & \\text{si } \\lambda \\neq 2, x_i < 0, \\\\[8pt]\n",
    " - \\ln (- x_i + 1) & \\text{si } \\lambda = 2, x_i < 0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Mientras que la transformación Box-Cox se define como:\n",
    "\n",
    "$$\n",
    "x_i^{(\\lambda)} =\n",
    "\\begin{cases}\n",
    "\\dfrac{x_i^\\lambda - 1}{\\lambda} & \\text{si } \\lambda \\neq 0, \\\\[8pt]\n",
    "\\ln{(x_i)} & \\text{si } \\lambda = 0,\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Box-Cox solo se puede aplicar a datos estrictamente positivos. En ambos métodos, la transformación está parametrizada por \\(\\lambda\\), que se determina mediante estimación de máxima verosimilitud. Aquí tienes un ejemplo de cómo usar Box-Cox para mapear muestras extraídas de una distribución logarítmica normal a una distribución normal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c51fc1a-ce79-4c2f-9457-6c4719666212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.28331718, 1.18092228, 0.84160269],\n",
       "       [0.94293279, 1.60960836, 0.3879099 ],\n",
       "       [1.35235668, 0.21715673, 1.09977091]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt = preprocessing.PowerTransformer(method='box-cox', standardize=False)\n",
    "X_lognormal = np.random.RandomState(616).lognormal(size=(3, 3))\n",
    "X_lognormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d634599-f8e9-45be-bd63-f9e79b97b000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.49024349,  0.17881995, -0.1563781 ],\n",
       "       [-0.05102892,  0.58863195, -0.57612414],\n",
       "       [ 0.69420009, -0.84857822,  0.10051454]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt.fit_transform(X_lognormal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573203e2-017a-48e0-b66a-5e38180f8861",
   "metadata": {},
   "source": [
    "Mientras que el ejemplo anterior establece la opción \"standardize\" en Falso, [PowerTransformer](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PowerTransformer.html#sklearn.preprocessing.PowerTransformer) aplicará por defecto una normalización de media cero y varianza unitaria a la salida transformada.\n",
    "\n",
    "A continuación, se presentan ejemplos de aplicar Box-Cox y Yeo-Johnson a varias distribuciones de probabilidad. Ten en cuenta que cuando se aplican a ciertas distribuciones, las transformaciones de potencia logran resultados muy similares a una distribución gaussiana, pero en otros casos, son ineficaces. Esto resalta la importancia de visualizar los datos antes y después de la transformación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d68df63-3bfd-4795-8223-cbf05a799c20",
   "metadata": {},
   "source": [
    "<figure> \n",
    "<center>\n",
    "<img src=\"https://scikit-learn.org/stable/_images/sphx_glr_plot_map_data_to_normal_001.png\"/>\n",
    "</center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae77faa-b12d-4c63-8798-57e33672e766",
   "metadata": {},
   "source": [
    "También es posible mapear los datos a una distribución normal utilizando `QuantileTransformer` estableciendo `output_distribution='normal'`. Usando el ejemplo anterior con el conjunto de datos iris:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7daa85fb-c618-4bb2-96fc-a7dab102b362",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anroj\\anaconda3\\envs\\Plotly\\Lib\\site-packages\\sklearn\\preprocessing\\_data.py:2627: UserWarning: n_quantiles (1000) is greater than the total number of samples (150). n_quantiles is set to n_samples.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4.3, 2. , 1. , 0.1],\n",
       "       [4.4, 2.2, 1.1, 0.1],\n",
       "       [4.4, 2.2, 1.2, 0.1],\n",
       "       [4.4, 2.2, 1.2, 0.1],\n",
       "       [4.5, 2.3, 1.3, 0.1],\n",
       "       [4.6, 2.3, 1.3, 0.2],\n",
       "       [4.6, 2.3, 1.3, 0.2],\n",
       "       [4.6, 2.3, 1.3, 0.2],\n",
       "       [4.6, 2.4, 1.3, 0.2],\n",
       "       [4.7, 2.4, 1.3, 0.2],\n",
       "       [4.7, 2.4, 1.3, 0.2],\n",
       "       [4.8, 2.5, 1.4, 0.2],\n",
       "       [4.8, 2.5, 1.4, 0.2],\n",
       "       [4.8, 2.5, 1.4, 0.2],\n",
       "       [4.8, 2.5, 1.4, 0.2],\n",
       "       [4.8, 2.5, 1.4, 0.2],\n",
       "       [4.9, 2.5, 1.4, 0.2],\n",
       "       [4.9, 2.5, 1.4, 0.2],\n",
       "       [4.9, 2.5, 1.4, 0.2],\n",
       "       [4.9, 2.6, 1.4, 0.2],\n",
       "       [4.9, 2.6, 1.4, 0.2],\n",
       "       [4.9, 2.6, 1.4, 0.2],\n",
       "       [5. , 2.6, 1.4, 0.2],\n",
       "       [5. , 2.6, 1.4, 0.2],\n",
       "       [5. , 2.7, 1.5, 0.2],\n",
       "       [5. , 2.7, 1.5, 0.2],\n",
       "       [5. , 2.7, 1.5, 0.2],\n",
       "       [5. , 2.7, 1.5, 0.2],\n",
       "       [5. , 2.7, 1.5, 0.2],\n",
       "       [5. , 2.7, 1.5, 0.2],\n",
       "       [5. , 2.7, 1.5, 0.2],\n",
       "       [5. , 2.7, 1.5, 0.2],\n",
       "       [5.1, 2.7, 1.5, 0.2],\n",
       "       [5.1, 2.8, 1.5, 0.2],\n",
       "       [5.1, 2.8, 1.5, 0.3],\n",
       "       [5.1, 2.8, 1.5, 0.3],\n",
       "       [5.1, 2.8, 1.5, 0.3],\n",
       "       [5.1, 2.8, 1.6, 0.3],\n",
       "       [5.1, 2.8, 1.6, 0.3],\n",
       "       [5.1, 2.8, 1.6, 0.3],\n",
       "       [5.1, 2.8, 1.6, 0.3],\n",
       "       [5.2, 2.8, 1.6, 0.4],\n",
       "       [5.2, 2.8, 1.6, 0.4],\n",
       "       [5.2, 2.8, 1.6, 0.4],\n",
       "       [5.2, 2.8, 1.7, 0.4],\n",
       "       [5.3, 2.8, 1.7, 0.4],\n",
       "       [5.4, 2.8, 1.7, 0.4],\n",
       "       [5.4, 2.9, 1.7, 0.4],\n",
       "       [5.4, 2.9, 1.9, 0.5],\n",
       "       [5.4, 2.9, 1.9, 0.6],\n",
       "       [5.4, 2.9, 3. , 1. ],\n",
       "       [5.4, 2.9, 3.3, 1. ],\n",
       "       [5.5, 2.9, 3.3, 1. ],\n",
       "       [5.5, 2.9, 3.5, 1. ],\n",
       "       [5.5, 2.9, 3.5, 1. ],\n",
       "       [5.5, 2.9, 3.6, 1. ],\n",
       "       [5.5, 2.9, 3.7, 1. ],\n",
       "       [5.5, 3. , 3.8, 1.1],\n",
       "       [5.5, 3. , 3.9, 1.1],\n",
       "       [5.6, 3. , 3.9, 1.1],\n",
       "       [5.6, 3. , 3.9, 1.2],\n",
       "       [5.6, 3. , 4. , 1.2],\n",
       "       [5.6, 3. , 4. , 1.2],\n",
       "       [5.6, 3. , 4. , 1.2],\n",
       "       [5.6, 3. , 4. , 1.2],\n",
       "       [5.7, 3. , 4. , 1.3],\n",
       "       [5.7, 3. , 4.1, 1.3],\n",
       "       [5.7, 3. , 4.1, 1.3],\n",
       "       [5.7, 3. , 4.1, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.3],\n",
       "       [5.8, 3. , 4.3, 1.3],\n",
       "       [5.8, 3. , 4.3, 1.3],\n",
       "       [5.8, 3. , 4.4, 1.3],\n",
       "       [5.8, 3. , 4.4, 1.3],\n",
       "       [5.8, 3. , 4.4, 1.3],\n",
       "       [5.8, 3. , 4.4, 1.4],\n",
       "       [5.8, 3. , 4.5, 1.4],\n",
       "       [5.9, 3. , 4.5, 1.4],\n",
       "       [5.9, 3. , 4.5, 1.4],\n",
       "       [5.9, 3. , 4.5, 1.4],\n",
       "       [6. , 3.1, 4.5, 1.4],\n",
       "       [6. , 3.1, 4.5, 1.4],\n",
       "       [6. , 3.1, 4.5, 1.4],\n",
       "       [6. , 3.1, 4.5, 1.5],\n",
       "       [6. , 3.1, 4.6, 1.5],\n",
       "       [6. , 3.1, 4.6, 1.5],\n",
       "       [6.1, 3.1, 4.6, 1.5],\n",
       "       [6.1, 3.1, 4.7, 1.5],\n",
       "       [6.1, 3.1, 4.7, 1.5],\n",
       "       [6.1, 3.1, 4.7, 1.5],\n",
       "       [6.1, 3.1, 4.7, 1.5],\n",
       "       [6.1, 3.2, 4.7, 1.5],\n",
       "       [6.2, 3.2, 4.8, 1.5],\n",
       "       [6.2, 3.2, 4.8, 1.5],\n",
       "       [6.2, 3.2, 4.8, 1.5],\n",
       "       [6.2, 3.2, 4.8, 1.6],\n",
       "       [6.3, 3.2, 4.9, 1.6],\n",
       "       [6.3, 3.2, 4.9, 1.6],\n",
       "       [6.3, 3.2, 4.9, 1.6],\n",
       "       [6.3, 3.2, 4.9, 1.7],\n",
       "       [6.3, 3.2, 4.9, 1.7],\n",
       "       [6.3, 3.2, 5. , 1.8],\n",
       "       [6.3, 3.2, 5. , 1.8],\n",
       "       [6.3, 3.2, 5. , 1.8],\n",
       "       [6.3, 3.3, 5. , 1.8],\n",
       "       [6.4, 3.3, 5.1, 1.8],\n",
       "       [6.4, 3.3, 5.1, 1.8],\n",
       "       [6.4, 3.3, 5.1, 1.8],\n",
       "       [6.4, 3.3, 5.1, 1.8],\n",
       "       [6.4, 3.3, 5.1, 1.8],\n",
       "       [6.4, 3.4, 5.1, 1.8],\n",
       "       [6.4, 3.4, 5.1, 1.8],\n",
       "       [6.5, 3.4, 5.1, 1.8],\n",
       "       [6.5, 3.4, 5.2, 1.9],\n",
       "       [6.5, 3.4, 5.2, 1.9],\n",
       "       [6.5, 3.4, 5.3, 1.9],\n",
       "       [6.5, 3.4, 5.3, 1.9],\n",
       "       [6.6, 3.4, 5.4, 1.9],\n",
       "       [6.6, 3.4, 5.4, 2. ],\n",
       "       [6.7, 3.4, 5.5, 2. ],\n",
       "       [6.7, 3.4, 5.5, 2. ],\n",
       "       [6.7, 3.4, 5.5, 2. ],\n",
       "       [6.7, 3.5, 5.6, 2. ],\n",
       "       [6.7, 3.5, 5.6, 2. ],\n",
       "       [6.7, 3.5, 5.6, 2.1],\n",
       "       [6.7, 3.5, 5.6, 2.1],\n",
       "       [6.7, 3.5, 5.6, 2.1],\n",
       "       [6.8, 3.5, 5.6, 2.1],\n",
       "       [6.8, 3.6, 5.7, 2.1],\n",
       "       [6.8, 3.6, 5.7, 2.1],\n",
       "       [6.9, 3.6, 5.7, 2.2],\n",
       "       [6.9, 3.6, 5.8, 2.2],\n",
       "       [6.9, 3.7, 5.8, 2.2],\n",
       "       [6.9, 3.7, 5.8, 2.3],\n",
       "       [7. , 3.7, 5.9, 2.3],\n",
       "       [7.1, 3.8, 5.9, 2.3],\n",
       "       [7.2, 3.8, 6. , 2.3],\n",
       "       [7.2, 3.8, 6. , 2.3],\n",
       "       [7.2, 3.8, 6.1, 2.3],\n",
       "       [7.3, 3.8, 6.1, 2.3],\n",
       "       [7.4, 3.8, 6.1, 2.3],\n",
       "       [7.6, 3.9, 6.3, 2.4],\n",
       "       [7.7, 3.9, 6.4, 2.4],\n",
       "       [7.7, 4. , 6.6, 2.4],\n",
       "       [7.7, 4.1, 6.7, 2.5],\n",
       "       [7.7, 4.2, 6.7, 2.5],\n",
       "       [7.9, 4.4, 6.9, 2.5]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantile_transformer = preprocessing.QuantileTransformer(\n",
    "    output_distribution='normal', random_state=0)\n",
    "X_trans = quantile_transformer.fit_transform(X)\n",
    "quantile_transformer.quantiles_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d10991-25b5-4d07-b249-50c80bca8cc0",
   "metadata": {},
   "source": [
    "Por lo tanto, la mediana de la entrada se convierte en la media de la salida, centrada en 0. La salida normal se recorta de modo que el mínimo y el máximo de la entrada, que corresponden a los cuantiles 1e-7 y 1 - 1e-7 respectivamente, no se vuelvan infinitos bajo la transformación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db27e20-976b-47d2-9bc2-109ccdfc3ce5",
   "metadata": {},
   "source": [
    "##   <span style=\"color:blue\">Normalización</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86366fd0-dcdf-43f1-a78c-d3568aa1ed03",
   "metadata": {},
   "source": [
    "La normalización es el proceso de escalar muestras individuales para que tengan una norma unitaria. Este proceso puede ser útil si planeas utilizar una forma cuadrática como el producto punto o cualquier otro núcleo para cuantificar la similitud entre cualquier par de muestras.\n",
    "\n",
    "Esta suposición es la base del Modelo de Espacio Vectorial que se utiliza a menudo en contextos de clasificación y agrupación de texto.\n",
    "\n",
    "La función [normalize](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.normalize.html#sklearn.preprocessing.normalize) proporciona una forma rápida y sencilla de realizar esta operación en un solo conjunto de datos similar a una matriz, ya sea utilizando las normas l1, l2 o máxima (max):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "78504b9a-02c4-423e-a8df-01e06604684e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.40824829, -0.40824829,  0.81649658],\n",
       "       [ 1.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.70710678, -0.70710678]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [[ 1., -1.,  2.],\n",
    "     [ 2.,  0.,  0.],\n",
    "     [ 0.,  1., -1.]]\n",
    "X_normalized = preprocessing.normalize(X, norm='l2')\n",
    "\n",
    "X_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405b9530-9f1a-446d-905f-312cdf75574c",
   "metadata": {},
   "source": [
    "El módulo de preprocesamiento también proporciona una clase de utilidad llamada [Normalizer](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.Normalizer.html#sklearn.preprocessing.Normalizer) que implementa la misma operación utilizando la API de transformadores (aunque el método fit es inútil en este caso: la clase no guarda ningún estado ya que esta operación trata las muestras de forma independiente).\n",
    "\n",
    "Por lo tanto, esta clase es adecuada para su uso en las primeras etapas de un [Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1c91d8-7910-437a-b635-4e6fba4a2161",
   "metadata": {},
   "source": [
    "normalizer = preprocessing.Normalizer().fit(X)  # fit does nothing\n",
    "normalizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd8050e-9c65-4fd3-9ce8-26c72fc9382d",
   "metadata": {},
   "source": [
    "La instancia del normalizador luego puede ser utilizada en vectores de muestra como cualquier otro transformador:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "01045f9f-9e2a-4442-bb58-10690176b805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.40824829, -0.40824829,  0.81649658],\n",
       "       [ 1.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.70710678, -0.70710678]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalizer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3f12361c-783a-49d6-9293-a3f2e04fa7e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.70710678,  0.70710678,  0.        ]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalizer.transform([[-1.,  1., 0.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57dfdfeb-87df-43c8-b442-96beb491296e",
   "metadata": {},
   "source": [
    "Nota: La normalización L2 también se conoce como preprocesamiento de signo espacial.\n",
    "\n",
    "Entrada dispersa\n",
    "\n",
    "`normalize` y `Normalizer` aceptan tanto matrices densas similares a arrays como matrices dispersas de `scipy.sparse` como entrada.\n",
    "\n",
    "Para entradas dispersas, los datos se convierten a la representación de Filas Comprimidas Dispersas (consultar `scipy.sparse.csr_matrix`) antes de ser alimentados a las eficientes rutinas de Cython. Para evitar copias innecesarias en la memoria, se recomienda elegir la representación CSR aguas arriba (es decir, antes) del proceso."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10674a0d-0ba7-4fd0-87bc-764d99c70a52",
   "metadata": {},
   "source": [
    "##   <span style=\"color:blue\">Codificación de características categóricas.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbcce6c-1ee0-43ae-8397-f628a980b6b5",
   "metadata": {},
   "source": [
    "A menudo, las características no se presentan como valores continuos, sino como categóricos. Por ejemplo, una persona podría tener características como [\"hombre\", \"mujer\"], [\"de Europa\", \"de EE. UU.\", \"de Asia\"], [\"usa Firefox\", \"usa Chrome\", \"usa Safari\", \"usa Internet Explorer\"]. Tales características se pueden codificar de manera eficiente como enteros, por ejemplo, [\"hombre\", \"de EE. UU.\", \"usa Internet Explorer\"] podría expresarse como [0, 1, 3], mientras que [\"mujer\", \"de Asia\", \"usa Chrome\"] sería [1, 2, 1].\n",
    "\n",
    "Para convertir características categóricas en tales códigos enteros, podemos utilizar el [OrdinalEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html#sklearn.preprocessing.OrdinalEncoder). Este estimador transforma cada característica categórica en una nueva característica de enteros (de 0 a n_categories - 1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c61ce0eb-77b0-42d2-b7a8-9cb3dfc2a064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OrdinalEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OrdinalEncoder</label><div class=\"sk-toggleable__content\"><pre>OrdinalEncoder()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "OrdinalEncoder()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = preprocessing.OrdinalEncoder()\n",
    "X = [['male', 'from US', 'uses Safari'], ['female', 'from Europe', 'uses Firefox']]\n",
    "enc.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "40b566b7-9604-4024-9707-9e2b11eba2c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 1.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.transform([['female', 'from US', 'uses Safari']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ebf113-9eae-4704-8342-d76bb527baa8",
   "metadata": {},
   "source": [
    "Sin embargo, esta representación entera no se puede utilizar directamente con todos los estimadores de scikit-learn, ya que estos esperan una entrada continua y podrían interpretar las categorías como ordenadas, lo cual a menudo no es deseado (es decir, el conjunto de navegadores se ordenó arbitrariamente).\n",
    "\n",
    "Por defecto, OrdinalEncoder también conservará los valores faltantes que están indicados por np.nan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "13e74437-25a8-4afa-be89-86477bcfa6f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.],\n",
       "       [ 0.],\n",
       "       [nan],\n",
       "       [ 0.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = preprocessing.OrdinalEncoder()\n",
    "X = [['male'], ['female'], [np.nan], ['female']]\n",
    "enc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc45e1b-44c5-45cb-b179-f076da50db3d",
   "metadata": {},
   "source": [
    "OrdinalEncoder proporciona un parámetro llamado 'encoded_missing_value' para codificar los valores faltantes sin necesidad de crear un pipeline y usar [SimpleImputer](https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html#sklearn.impute.SimpleImputer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c4c083a1-2fe7-42c5-b97c-d28adc9e9af8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.],\n",
       "       [ 0.],\n",
       "       [-1.],\n",
       "       [ 0.]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = preprocessing.OrdinalEncoder(encoded_missing_value=-1)\n",
    "X = [['male'], ['female'], [np.nan], ['female']]\n",
    "enc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c86ce3e-122b-4f2e-afda-4b87e19484ae",
   "metadata": {},
   "source": [
    "El procesamiento anterior es equivalente a la siguiente canalización (pipeline):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f3214e6d-288e-44db-86a1-598aa2681a46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.],\n",
       "       [ 0.],\n",
       "       [-1.],\n",
       "       [ 0.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "enc = Pipeline(steps=[\n",
    "    (\"encoder\", preprocessing.OrdinalEncoder()),\n",
    "    (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=-1)),\n",
    "])\n",
    "enc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0e8d86-d553-4a77-a39b-0a5cc97ba779",
   "metadata": {},
   "source": [
    "Otra posibilidad para convertir características categóricas en características que se pueden utilizar con estimadores de scikit-learn es utilizar una codificación uno-de-K, también conocida como codificación one-hot o codificación dummy. Este tipo de codificación se puede obtener con OneHotEncoder, que transforma cada característica categórica con n_categories posibles valores en n_categories características binarias, en las cuales una de ellas es 1 y todas las demás son 0.\n",
    "\n",
    "Continuando con el ejemplo anterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eb3d5f54-26a1-460d-9e1b-790578dd455b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneHotEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "OneHotEncoder()"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = preprocessing.OneHotEncoder()\n",
    "X = [['male', 'from US', 'uses Safari'], ['female', 'from Europe', 'uses Firefox']]\n",
    "enc.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "92b011d1-c411-49fe-b8ba-862320f20672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 1., 0., 1.],\n",
       "       [0., 1., 1., 0., 0., 1.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.transform([['female', 'from US', 'uses Safari'],\n",
    "               ['male', 'from Europe', 'uses Safari']]).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553f3b94-934f-4cb9-a4e6-e59a54b68fc0",
   "metadata": {},
   "source": [
    "Por defecto, los valores que cada característica puede tomar se infieren automáticamente a partir del conjunto de datos y se pueden encontrar en el atributo categories_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c89dd14a-09d9-422e-abd2-7f4151f17541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['female', 'male'], dtype=object),\n",
       " array(['from Europe', 'from US'], dtype=object),\n",
       " array(['uses Firefox', 'uses Safari'], dtype=object)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.categories_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33587280-f828-4e19-8f94-0018ffc4d435",
   "metadata": {},
   "source": [
    "Es posible especificarlo explícitamente utilizando el parámetro \"categorías\". En nuestro conjunto de datos, hay dos géneros, cuatro continentes posibles y cuatro navegadores web."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3406f349-0b7b-4eab-b452-d913aef957c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneHotEncoder(categories=[[&#x27;female&#x27;, &#x27;male&#x27;],\n",
       "                          [&#x27;from Africa&#x27;, &#x27;from Asia&#x27;, &#x27;from Europe&#x27;,\n",
       "                           &#x27;from US&#x27;],\n",
       "                          [&#x27;uses Chrome&#x27;, &#x27;uses Firefox&#x27;, &#x27;uses IE&#x27;,\n",
       "                           &#x27;uses Safari&#x27;]])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(categories=[[&#x27;female&#x27;, &#x27;male&#x27;],\n",
       "                          [&#x27;from Africa&#x27;, &#x27;from Asia&#x27;, &#x27;from Europe&#x27;,\n",
       "                           &#x27;from US&#x27;],\n",
       "                          [&#x27;uses Chrome&#x27;, &#x27;uses Firefox&#x27;, &#x27;uses IE&#x27;,\n",
       "                           &#x27;uses Safari&#x27;]])</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "OneHotEncoder(categories=[['female', 'male'],\n",
       "                          ['from Africa', 'from Asia', 'from Europe',\n",
       "                           'from US'],\n",
       "                          ['uses Chrome', 'uses Firefox', 'uses IE',\n",
       "                           'uses Safari']])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genders = ['female', 'male']\n",
    "locations = ['from Africa', 'from Asia', 'from Europe', 'from US']\n",
    "browsers = ['uses Chrome', 'uses Firefox', 'uses IE', 'uses Safari']\n",
    "enc = preprocessing.OneHotEncoder(categories=[genders, locations, browsers])\n",
    "# Note that for there are missing categorical values for the 2nd and 3rd\n",
    "# feature\n",
    "X = [['male', 'from US', 'uses Safari'], ['female', 'from Europe', 'uses Firefox']]\n",
    "enc.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c6a97121-f511-4e7d-aee1-43d2d00ee7f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 1., 0., 0., 1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.transform([['female', 'from Asia', 'uses Chrome']]).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb475b0-9dfd-41b2-8ba8-277433c47cf1",
   "metadata": {},
   "source": [
    "Si existe la posibilidad de que los datos de entrenamiento puedan contener características categóricas faltantes, a menudo es mejor especificar `handle_unknown='infrequent_if_exist'` en lugar de establecer las categorías manualmente como se indicó anteriormente. Cuando se especifica `handle_unknown='infrequent_if_exist'` y se encuentran categorías desconocidas durante la transformación, no se generará ningún error, pero las columnas codificadas en one-hot resultantes para esta característica serán todas ceros o se considerarán como una categoría infrecuente si está habilitada (esto solo es compatible con la codificación one-hot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0ee5bb52-238c-41cc-86aa-2992c13147c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneHotEncoder(handle_unknown=&#x27;infrequent_if_exist&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;infrequent_if_exist&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "OneHotEncoder(handle_unknown='infrequent_if_exist')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = preprocessing.OneHotEncoder(handle_unknown='infrequent_if_exist')\n",
    "X = [['male', 'from US', 'uses Safari'], ['female', 'from Europe', 'uses Firefox']]\n",
    "enc.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "09414d47-647c-464d-bb08-749eb01c086f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.transform([['female', 'from Asia', 'uses Chrome']]).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95c9495-3c2e-49ae-830b-5c46655efb6f",
   "metadata": {},
   "source": [
    "También es posible codificar cada columna en n_categories - 1 columnas en lugar de n_categories columnas utilizando el parámetro \"drop\". Este parámetro permite al usuario especificar una categoría para que se elimine de cada característica. Esto es útil para evitar la multicolinealidad en la matriz de entrada en algunos clasificadores. Esta funcionalidad es útil, por ejemplo, cuando se utiliza una regresión no regularizada (LinearRegression), ya que la multicolinealidad haría que la matriz de covarianza no sea invertible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "265f17aa-a1e0-47e9-9b0d-6d299b38b7e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['female', 'male'], dtype=object),\n",
       " array(['from Europe', 'from US'], dtype=object),\n",
       " array(['uses Firefox', 'uses Safari'], dtype=object)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [['male', 'from US', 'uses Safari'],\n",
    "     ['female', 'from Europe', 'uses Firefox']]\n",
    "drop_enc = preprocessing.OneHotEncoder(drop='first').fit(X)\n",
    "drop_enc.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e6cb30dc-976c-4c24-aa72-805700886920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_enc.transform(X).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9a98a0-b1ca-4277-b3ba-6580638d9682",
   "metadata": {},
   "source": [
    "Uno podría querer eliminar una de las dos columnas solo para las características con 2 categorías. En este caso, puedes configurar el parámetro `drop='if_binary'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "495c8210-482c-48e9-b886-80c110874a54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['female', 'male'], dtype=object),\n",
       " array(['Asia', 'Europe', 'US'], dtype=object),\n",
       " array(['Chrome', 'Firefox', 'Safari'], dtype=object)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [['male', 'US', 'Safari'],\n",
    "     ['female', 'Europe', 'Firefox'],\n",
    "     ['female', 'Asia', 'Chrome']]\n",
    "drop_enc = preprocessing.OneHotEncoder(drop='if_binary').fit(X)\n",
    "drop_enc.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ffcf0e1d-8c35-43bd-b0e1-c2b75eb54c17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 1., 0., 0., 1.],\n",
       "       [0., 0., 1., 0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_enc.transform(X).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a008b59-ec00-409b-a766-c1f11b93c03c",
   "metadata": {},
   "source": [
    "En la matriz X transformada, la primera columna es la codificación de la característica con categorías \"masculino\"/\"femenino\", mientras que las 6 columnas restantes son la codificación de las 2 características, cada una con 3 categorías respectivamente.\n",
    "\n",
    "Cuando `handle_unknown='ignore'` y `drop` no es `None`, las categorías desconocidas se codificarán como todo ceros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "62f30b62-7cfb-4713-be73-ddb8c5eb042f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anroj\\anaconda3\\envs\\Plotly\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:202: UserWarning: Found unknown categories in columns [0, 1, 2] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_enc = preprocessing.OneHotEncoder(drop='first',\n",
    "                                       handle_unknown='ignore').fit(X)\n",
    "X_test = [['unknown', 'America', 'IE']]\n",
    "drop_enc.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccd88ce-3e5a-4e88-9098-1d02c2ca6499",
   "metadata": {},
   "source": [
    "Todas las categorías en X_test son desconocidas durante la transformación y se mapearán como todos ceros. Esto significa que las categorías desconocidas tendrán el mismo mapeo que la categoría eliminada. [OneHotEncoder.inverse_transform](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder.inverse_transform) mapeará todos los ceros a la categoría eliminada si una categoría es eliminada y a 'None' si una categoría no es eliminada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "60b9d8ac-7b68-46e7-a81b-8c17f960d4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anroj\\anaconda3\\envs\\Plotly\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:202: UserWarning: Found unknown categories in columns [0, 1, 2] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_enc = preprocessing.OneHotEncoder(drop='if_binary', sparse_output=False,\n",
    "                                       handle_unknown='ignore').fit(X)\n",
    "X_test = [['unknown', 'America', 'IE']]\n",
    "X_trans = drop_enc.transform(X_test)\n",
    "X_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b5793787-d5f5-40c4-ad06-c6e7eeae2a30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['female', None, None]], dtype=object)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_enc.inverse_transform(X_trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3336ba-9c2f-40c9-8f5b-2aa3e492725e",
   "metadata": {},
   "source": [
    "[OneHotEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder) admite características categóricas con valores faltantes al considerar los valores faltantes como una categoría adicional:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8c1ae381-3763-42fb-b8cc-57bd90f14793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['female', 'male', nan], dtype=object),\n",
       " array(['Firefox', 'Safari', None], dtype=object)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [['male', 'Safari'],\n",
    "     ['female', None],\n",
    "     [np.nan, 'Firefox']]\n",
    "enc = preprocessing.OneHotEncoder(handle_unknown='error').fit(X)\n",
    "enc.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3ebd5f8d-18e8-4a88-812d-26bc82555cf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 1., 1., 0., 0.]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.transform(X).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98d61b8-66c3-4e42-b506-f46f59ded8d2",
   "metadata": {},
   "source": [
    "Si una característica contiene tanto np.nan como None, se considerarán categorías separadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "274cdf39-d128-43bb-aec3-1131a5a3567e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['Firefox', 'Safari', None, nan], dtype=object)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [['Safari'], [None], [np.nan], ['Firefox']]\n",
    "enc = preprocessing.OneHotEncoder(handle_unknown='error').fit(X)\n",
    "enc.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fcaf9c64-ab2e-4b73-8edc-ebd29158ae1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.transform(X).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a15ad9-8cad-41a5-89b6-cd9f34920a2a",
   "metadata": {},
   "source": [
    "Mira [Cargando características desde diccionarios](https://scikit-learn.org/stable/modules/feature_extraction.html#dict-feature-extraction) para características categóricas que se representan como un diccionario en lugar de escalares."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ff41e4-f690-410a-a040-49961ade922f",
   "metadata": {},
   "source": [
    "###   <span style=\"color:blue\">Categorías no frecuentes</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7ecc6b-f29d-468e-b0cc-d5d91e70aea9",
   "metadata": {},
   "source": [
    "[OneHotEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder) y [OrdinalEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html#sklearn.preprocessing.OrdinalEncoder) admiten la agregación de categorías poco frecuentes en una única salida para cada característica. Los parámetros para habilitar la recopilación de categorías poco frecuentes son min_frequency y max_categories.\n",
    "\n",
    "- min_frequency es un número entero mayor o igual a 1, o un número decimal en el intervalo (0.0, 1.0). Si min_frequency es un número entero, se considerarán categorías con una cardinalidad menor que min_frequency como poco frecuentes. Si min_frequency es un número decimal, se considerarán categorías con una cardinalidad menor que esta fracción del número total de muestras como poco frecuentes. El valor predeterminado es 1, lo que significa que cada categoría se codifica por separado.\n",
    "\n",
    "- max_categories es None o cualquier número entero mayor que 1. Este parámetro establece un límite superior para el número de características de salida para cada característica de entrada. max_categories incluye la característica que combina las categorías poco frecuentes.\n",
    "\n",
    "En el siguiente ejemplo con OrdinalEncoder, las categorías 'dog' y 'snake' se consideran poco frecuentes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c522f053-0909-4d00-8cac-3df54bb5ab89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['dog', 'snake'], dtype=object)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([['dog'] * 5 + ['cat'] * 20 + ['rabbit'] * 10 +\n",
    "              ['snake'] * 3], dtype=object).T\n",
    "enc = preprocessing.OrdinalEncoder(min_frequency=6).fit(X)\n",
    "enc.infrequent_categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82186c30-bbff-460b-bc14-ccc6ce6b8345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [2.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.transform(np.array([['dog'], ['cat'], ['rabbit'], ['snake']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d39de6-f83c-4bba-93bf-63c814ead011",
   "metadata": {},
   "source": [
    "El parámetro `max_categories` de `OrdinalEncoder` no tiene en cuenta las categorías faltantes o desconocidas. Establecer `unknown_value` o `encoded_missing_value` como un número entero aumentará el número de códigos enteros únicos en uno cada uno. Esto puede resultar en hasta `max_categories + 2` códigos enteros. En el siguiente ejemplo, \"a\" y \"d\" se consideran poco frecuentes y se agrupan en una sola categoría, \"b\" y \"c\" son sus propias categorías, los valores desconocidos se codifican como 3 y los valores faltantes se codifican como 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "976125b4-5783-49bf-b217-1b657931c3c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [3.],\n",
       "       [4.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.array(\n",
    "    [[\"a\"] * 5 + [\"b\"] * 20 + [\"c\"] * 10 + [\"d\"] * 3 + [np.nan]],\n",
    "    dtype=object).T\n",
    "enc = preprocessing.OrdinalEncoder(\n",
    "    handle_unknown=\"use_encoded_value\", unknown_value=3,\n",
    "    max_categories=3, encoded_missing_value=4)\n",
    "_ = enc.fit(X_train)\n",
    "X_test = np.array([[\"a\"], [\"b\"], [\"c\"], [\"d\"], [\"e\"], [np.nan]], dtype=object)\n",
    "enc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f835a80a-0cfa-4f81-ad51-87f013c023c5",
   "metadata": {},
   "source": [
    "De manera similar, OneHotEncoder se puede configurar para agrupar categorías poco frecuentes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0ad8188-0619-4294-99cf-86d811367a87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = preprocessing.OneHotEncoder(min_frequency=6, sparse_output=False).fit(X)\n",
    "enc.infrequent_categories_\n",
    "enc.transform(np.array([['dog'], ['cat'], ['rabbit'], ['snake']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e20975-b9b6-4eb3-9601-b0778b9e2fc0",
   "metadata": {},
   "source": [
    "Al establecer `handle_unknown` en 'infrequent_if_exist', las categorías desconocidas se considerarán como infrecuentes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ed73fb9-5229-4f38-9eac-7f8066d7ee86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = preprocessing.OneHotEncoder(\n",
    "    handle_unknown='infrequent_if_exist', sparse_output=False, min_frequency=6)\n",
    "enc = enc.fit(X)\n",
    "enc.transform(np.array([['dragon']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7c316c-598f-482b-a5cd-42056f160966",
   "metadata": {},
   "source": [
    "[OneHotEncoder.get_feature_names_out](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder.get_feature_names_out) utiliza 'infrequent' como el nombre de característica infrecuente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1892308-6150-4209-aa3c-44bcd0b308e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['x0_cat', 'x0_rabbit', 'x0_infrequent_sklearn'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59586c9-e127-4798-b138-5a8f36366891",
   "metadata": {},
   "source": [
    "Cuando 'handle_unknown' se establece en 'infrequent_if_exist' y se encuentra una categoría desconocida en la transformación:\n",
    "\n",
    "- Si el soporte para categorías infrecuentes no estaba configurado o no había categorías infrecuentes durante el entrenamiento, las columnas codificadas en one-hot resultantes para esta característica serán todos ceros. En la transformación inversa, una categoría desconocida se denotará como None.\n",
    "\n",
    "- Si hay una categoría infrecuente durante el entrenamiento, la categoría desconocida se considerará infrecuente. En la transformación inversa, se utilizará 'infrequent_sklearn' para representar la categoría infrecuente.\n",
    "\n",
    "Las categorías infrecuentes también se pueden configurar utilizando 'max_categories'. En el siguiente ejemplo, configuramos 'max_categories=2' para limitar el número de características en la salida. Esto dará como resultado que todas las categorías excepto la 'cat' se consideren infrecuentes, lo que conduce a dos características: una para 'cat' y otra para las categorías infrecuentes, que son todas las demás."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e695eb70-562f-40ca-9a81-0a398f138589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = preprocessing.OneHotEncoder(max_categories=2, sparse_output=False)\n",
    "enc = enc.fit(X)\n",
    "enc.transform([['dog'], ['cat'], ['rabbit'], ['snake']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8215c524-ce0b-44e9-905e-41b50b204254",
   "metadata": {},
   "source": [
    "Si tanto max_categories como min_frequency tienen valores no predeterminados, entonces las categorías se seleccionan en función de min_frequency primero y se mantienen max_categories categorías. En el siguiente ejemplo, min_frequency=4 considera que solo \"snake\" es poco frecuente, pero max_categories=3 también fuerza a que \"dog\" sea poco frecuente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1abf8b0f-9f57-4742-8a2a-128d776e7012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc = preprocessing.OneHotEncoder(min_frequency=4, max_categories=3, sparse_output=False)\n",
    "enc = enc.fit(X)\n",
    "enc.transform([['dog'], ['cat'], ['rabbit'], ['snake']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54584872-806a-477e-aa4a-b431813335dc",
   "metadata": {},
   "source": [
    "Si existen categorías poco frecuentes con la misma cardinalidad en el umbral máximo de categorías (max_categories), entonces las primeras max_categories se seleccionan en función del orden léxico. En el siguiente ejemplo, \"b\", \"c\" y \"d\" tienen la misma cardinalidad y con max_categories=2, \"b\" y \"c\" son poco frecuentes porque tienen un orden léxico más alto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02a0a597-d7ab-49fb-b1e3-2f327b271a36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['b', 'c'], dtype=object)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.asarray([[\"a\"] * 20 + [\"b\"] * 10 + [\"c\"] * 10 + [\"d\"] * 10], dtype=object).T\n",
    "enc = preprocessing.OneHotEncoder(max_categories=3).fit(X)\n",
    "enc.infrequent_categories_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093fadb2-5096-430e-8d65-5b5d5a40d30b",
   "metadata": {},
   "source": [
    "###   <span style=\"color:blue\">Codificador de Objetivo</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf99867-8967-4fe7-9e9a-f3bf4d8e1b5e",
   "metadata": {},
   "source": [
    "El [TargetEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.TargetEncoder.html#sklearn.preprocessing.TargetEncoder) utiliza la media del objetivo condicionada a la característica categórica para codificar categorías no ordenadas, es decir, categorías nominales [PAR](https://scikit-learn.org/stable/modules/preprocessing.html#par) [MIC](https://scikit-learn.org/stable/modules/preprocessing.html#mic). Este esquema de codificación es útil con características categóricas de alta cardinalidad, donde la codificación one-hot inflaría el espacio de características, lo que haría que fuera más costoso para un modelo posterior procesarlos. Un ejemplo clásico de categorías de alta cardinalidad son las basadas en ubicación, como el código postal o la región. Para el objetivo de clasificación binaria, la codificación objetivo se da por:\n",
    "\n",
    "$$\n",
    "S_i = \\lambda_i\\frac{n_{iY}}{n_i} + (1 - \\lambda_i)\\frac{n_Y}{n}\n",
    "$$\n",
    "\n",
    "donde $S_i$ es la codificación para la categoría i, $n_{iY}$ es el número de observaciones con Y=1 y categoría i, $n_i$ es el número de observaciones con categoría i, $n_Y$ es el número de observaciones con $Y=1$, $n$ es el número de observaciones, y $\\lambda_i$ es un factor de contracción para la categoría $i$.\n",
    "\n",
    "El factor de contracción se calcula de la siguiente manera:\n",
    "$$\n",
    "\\lambda_i = \\frac{n_i}{m + n_i}\n",
    "$$\n",
    "\n",
    "donde $m$ es un factor de suavizado, que se controla con el parámetro de suavizado en [TargetEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.TargetEncoder.html#sklearn.preprocessing.TargetEncoder). Factores de suavizado grandes darán más peso a la media global. Cuando smooth=\"auto\", el factor de suavizado se calcula como una estimación de Bayes empírica: $m=\\sigma_i^2/\\tau^2$, donde $\\sigma_i^2$ es la varianza de y con la categoría $i$ y $\\tau^2$ es la varianza global de y.\n",
    "\n",
    "Para objetivos continuos, la formulación es similar a la clasificación binaria:\n",
    "\n",
    "$$\n",
    "S_i = \\lambda_i\\frac{\\sum_{k\\in L_i}Y_k}{n_i} + (1 - \\lambda_i)\\frac{\\sum_{k=1}^{n}Y_k}{n}\n",
    "$$\n",
    "\n",
    "donde $L_i$ es el conjunto de observaciones con categoría $i$ y $n_i$ es el número de observaciones con categoría $i$.\n",
    "\n",
    "[fit_transform](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.TargetEncoder.html#sklearn.preprocessing.TargetEncoder.fit_transform) se basa internamente en un esquema de ajuste cruzado para evitar que la información del objetivo se filtre en la representación de tiempo de entrenamiento, especialmente para variables categóricas de alta cardinalidad no informativas, y ayudar a evitar que el modelo posterior se sobreajuste a correlaciones espurias. Tenga en cuenta que como resultado, fit(X, y).transform(X) no es igual a fit_transform(X, y). En fit_transform, los datos de entrenamiento se dividen en k pliegues (determinados por el parámetro cv) y se codifica cada pliegue utilizando las codificaciones entrenadas en los otros k-1 pliegues. El siguiente diagrama muestra el esquema de ajuste cruzado en fit_transform con el valor predeterminado cv=5:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526bd6e1-b566-4841-bebc-a08fdb4cb9e6",
   "metadata": {},
   "source": [
    "<figure> \n",
    "<center>\n",
    "<img src=\"https://scikit-learn.org/stable/_images/target_encoder_cross_validation.svg\"/>\n",
    "</center>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c6823c-035c-468f-bad6-b3fefcb7cd34",
   "metadata": {},
   "source": [
    "[fit_transform](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.TargetEncoder.html#sklearn.preprocessing.TargetEncoder.fit_transform) también aprende una codificación de 'datos completos' utilizando todo el conjunto de entrenamiento. Esto nunca se utiliza en `fit_transform`, pero se guarda en el atributo `encodings_` para su uso cuando se llama a [transform](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.TargetEncoder.html#sklearn.preprocessing.TargetEncoder.transform). Tenga en cuenta que las codificaciones aprendidas para cada pliegue durante el esquema de ajuste cruzado no se guardan en un atributo.\n",
    "\n",
    "El método [fit](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.TargetEncoder.html#sklearn.preprocessing.TargetEncoder.fit) no utiliza ningún esquema de ajuste cruzado y aprende una codificación en todo el conjunto de entrenamiento, que se utiliza para codificar las categorías en [transform](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.TargetEncoder.html#sklearn.preprocessing.TargetEncoder.transform). Esta codificación es la misma que la codificación de 'datos completos' aprendida en [fit_transform](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.TargetEncoder.html#sklearn.preprocessing.TargetEncoder.fit_transform)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab397131-bdcf-42fd-bd6e-237fc1c786a5",
   "metadata": {},
   "source": [
    "#### Nota\n",
    "\n",
    "TargetEncoder considera los valores faltantes, como np.nan o None, como otra categoría y los codifica como cualquier otra categoría. Las categorías que no se ven durante el ajuste se codifican con la media del objetivo, es decir, target_mean_."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb23dbd-f67e-4e1a-a192-25a845f9211b",
   "metadata": {},
   "source": [
    "#### Ejemplos:\n",
    "\n",
    "- [Comparación de Target Encoder con Otros Codificadores](https://scikit-learn.org/stable/auto_examples/preprocessing/plot_target_encoder.html#sphx-glr-auto-examples-preprocessing-plot-target-encoder-py)\n",
    "\n",
    "- [Ajuste Cruzado Interno de Target Encoder](https://scikit-learn.org/stable/auto_examples/preprocessing/plot_target_encoder_cross_val.html#sphx-glr-auto-examples-preprocessing-plot-target-encoder-cross-val-py)\n",
    "\n",
    "#### Referencias\n",
    "\n",
    "[Micci-Barreca, Daniele. \"Un esquema de preprocesamiento para atributos categóricos de alta cardinalidad en problemas de clasificación y predicción\" SIGKDD Explor. Newsl. 3, 1 (julio de 2001), 27–32.](https://doi.org/10.1145/507533.507538)\n",
    "\n",
    "[Pargent, F., Pfisterer, F., Thomas, J. et al. \"La codificación objetivo regularizada supera a los métodos tradicionales en el aprendizaje automático supervisado con características de alta cardinalidad\" Comput Stat 37, 2671–2692 (2022)](https://link.springer.com/article/10.1007/s00180-022-01207-6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a60ec55-b6d3-4a11-809e-11a8c0720711",
   "metadata": {},
   "source": [
    "##   <span style=\"color:blue\">Discretización</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d370eb17-efb9-4eb8-94ea-901c7274795d",
   "metadata": {},
   "source": [
    "La discretización (también conocida como cuantificación o partición) proporciona una manera de dividir las características continuas en valores discretos. Algunos conjuntos de datos con características continuas pueden beneficiarse de la discretización, ya que esta puede transformar el conjunto de datos de atributos continuos en uno con atributos nominales únicamente.\n",
    "\n",
    "Las características discretizadas codificadas con one-hot encoding pueden hacer que un modelo sea más expresivo, al tiempo que mantienen su interpretabilidad. Por ejemplo, el preprocesamiento con un discretizador puede introducir no linealidad en modelos lineales. Para posibilidades más avanzadas, especialmente las más suaves, consulta la [generación de características polinómicas](https://scikit-learn.org/stable/modules/preprocessing.html#generating-polynomial-features) más abajo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f9d2ad-713c-483d-9d51-561304d6ab5f",
   "metadata": {},
   "source": [
    "###   <span style=\"color:blue\">Discretización K-bins</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550cde89-13e8-469e-a30f-34dc9c0b193f",
   "metadata": {},
   "source": [
    "[KBinsDiscretizer](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.KBinsDiscretizer.html#sklearn.preprocessing.KBinsDiscretizer) discretiza las características en k contenedores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c97961e4-2fef-470d-96e7-3b279dc4dcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[ -3., 5., 15 ],\n",
    "              [  0., 6., 14 ],\n",
    "              [  6., 3., 11 ]])\n",
    "est = preprocessing.KBinsDiscretizer(n_bins=[3, 2, 2], encode='ordinal').fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cacf0c-e845-4ae3-86eb-a2dc47e80b42",
   "metadata": {},
   "source": [
    "De forma predeterminada, la salida se codifica en un formato one-hot en una matriz dispersa (ver Codificación de características categóricas) y esto se puede configurar con el parámetro \"encode\". Para cada característica, los límites de los intervalos se calculan durante el ajuste (fit) y, junto con el número de intervalos, definirán los intervalos. Por lo tanto, para el ejemplo actual, estos intervalos se definen como:\n",
    "\n",
    "- Carácterística 1 ${[-\\infty, -1), [-1, 2), [2, \\infty)}$\n",
    "- Carácterística 2 ${[-\\infty, 5), [5, \\infty)}$\n",
    "- Carácterística 3 ${[-\\infty, 14), [14, \\infty)}$\n",
    "\n",
    "Basándose en estos intervalos de intervalos, X se transforma de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3f40dc1-c5ac-4364-9b24-eb09b0d83858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [2., 0., 0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est.transform(X)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969165d7-e533-478d-8bc7-f3609dadfaf5",
   "metadata": {},
   "source": [
    "El conjunto de datos resultante contiene atributos ordinales que pueden ser utilizados posteriormente en un [Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline).\n",
    "\n",
    "La discretización es similar a la construcción de histogramas para datos continuos. Sin embargo, los histogramas se centran en contar características que caen en bins específicos, mientras que la discretización se centra en asignar valores de características a estos bins.\n",
    "\n",
    "`KBinsDiscretizer` implementa diferentes estrategias de particionamiento, que pueden seleccionarse con el parámetro `strategy`. La estrategia 'uniforme' utiliza bins de ancho constante. La estrategia 'cuantil' utiliza los valores de los cuantiles para tener bins igualmente poblados en cada característica. La estrategia 'kmeans' define bins basados en un procedimiento de agrupamiento k-means realizado en cada característica de forma independiente.\n",
    "\n",
    "Ten en cuenta que puedes especificar bins personalizados pasando una función llamable que defina la estrategia de discretización a [FunctionTransformer](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.FunctionTransformer.html#sklearn.preprocessing.FunctionTransformer). Por ejemplo, podemos utilizar la función de Pandas [pandas.cut](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.cut.html#pandas.cut):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f229d46-88a4-49d7-8b41-d8b49c61d1ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['infant', 'kid', 'teen', 'adult', 'senior citizen']\n",
       "Categories (5, object): ['infant' < 'kid' < 'teen' < 'adult' < 'senior citizen']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "bins = [0, 1, 13, 20, 60, np.inf]\n",
    "labels = ['infant', 'kid', 'teen', 'adult', 'senior citizen']\n",
    "transformer = preprocessing.FunctionTransformer(\n",
    "    pd.cut, kw_args={'bins': bins, 'labels': labels, 'retbins': False}\n",
    ")\n",
    "X = np.array([0.2, 2, 15, 25, 97])\n",
    "transformer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed73008-ed68-4a8e-8f4c-094f9eb83068",
   "metadata": {},
   "source": [
    "#### Ejemplos\n",
    "\n",
    "- [Utilizando KBinsDiscretizer para discretizar características continuas](https://scikit-learn.org/stable/auto_examples/preprocessing/plot_discretization.html#sphx-glr-auto-examples-preprocessing-plot-discretization-py)\n",
    "- [Discretización de características](https://scikit-learn.org/stable/auto_examples/preprocessing/plot_discretization_classification.html#sphx-glr-auto-examples-preprocessing-plot-discretization-classification-py)\n",
    "- [Demostración de las diferentes estrategias de KBinsDiscretizer](https://scikit-learn.org/stable/auto_examples/preprocessing/plot_discretization_strategies.html#sphx-glr-auto-examples-preprocessing-plot-discretization-strategies-py)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56faa8be-ebc4-4b98-88e6-2b43b9576fdf",
   "metadata": {},
   "source": [
    "###   <span style=\"color:blue\">Binzarización de características</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b262300-f5e8-410e-a2f0-2ca35bba6a92",
   "metadata": {},
   "source": [
    "La binarización de características es el proceso de aplicar un umbral a las características numéricas para obtener valores booleanos. Esto puede ser útil para estimadores probabilísticos posteriores que hacen suposiciones de que los datos de entrada se distribuyen según una distribución de Bernoulli multivariante. Por ejemplo, este es el caso de [BernoulliRBM](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.BernoulliRBM.html#sklearn.neural_network.BernoulliRBM).\n",
    "\n",
    "También es común en la comunidad de procesamiento de texto utilizar valores de características binarias (probablemente para simplificar el razonamiento probabilístico), incluso si las cuentas normalizadas (también conocidas como frecuencias de términos) o las características valoradas con TF-IDF a menudo funcionan ligeramente mejor en la práctica.\n",
    "\n",
    "Al igual que con el Normalizer, la clase de utilidad Binarizer está diseñada para ser utilizada en las primeras etapas de un Pipeline. El método `fit` no hace nada, ya que cada muestra se trata de forma independiente de las demás:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99e37ed5-1d83-44da-87b5-6e273a7cc41f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Binarizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Binarizer</label><div class=\"sk-toggleable__content\"><pre>Binarizer()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Binarizer()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [[ 1., -1.,  2.],\n",
    "     [ 2.,  0.,  0.],\n",
    "     [ 0.,  1., -1.]]\n",
    "\n",
    "binarizer = preprocessing.Binarizer().fit(X)  # fit does nothing\n",
    "binarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66581075-7643-4e51-8f0f-e64a6ec04769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binarizer.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a521a7-982f-44ab-8fe4-f05a21dadcda",
   "metadata": {},
   "source": [
    "Es posible ajustar el umbral del binarizador:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62f4e345-b713-4755-9800-5931b0d78f57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binarizer = preprocessing.Binarizer(threshold=1.1)\n",
    "binarizer.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfe78db-cd7b-4de8-b165-aa6af70c3066",
   "metadata": {},
   "source": [
    "En cuanto a la clase Normalizer, el módulo de preprocesamiento proporciona una función complementaria llamada \"binarize\" que se utiliza cuando no es necesario utilizar la API de transformadores.\n",
    "\n",
    "Ten en cuenta que \"Binarizer\" es similar a \"KBinsDiscretizer\" cuando \"k = 2\", y cuando el borde del bin está en el valor del umbral.\n",
    "\n",
    "#### Entrada dispersa\n",
    "\n",
    "[binarize](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.binarize.html#sklearn.preprocessing.binarize) y [Binarizer](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.Binarizer.html#sklearn.preprocessing.Binarizer) aceptan tanto matrices densas similares a matrices como matrices dispersas de \"scipy.sparse\" como entrada.\n",
    "\n",
    "Para entradas dispersas, los datos se convierten a la representación de \"Compressed Sparse Rows\" (ver \"scipy.sparse.csr_matrix\"). Para evitar copias de memoria innecesarias, se recomienda elegir la representación CSR en las etapas anteriores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f91638-7c49-4aeb-b8a7-0ed33ed09e43",
   "metadata": {},
   "source": [
    "##   <span style=\"color:blue\">Imputación de valores faltantes</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3b8f82-c1e3-49c1-ac0e-64e42f84fcb1",
   "metadata": {},
   "source": [
    "Las herramientas para la imputación de valores faltantes se discuten en [Imputación de valores faltantes](https://scikit-learn.org/stable/modules/impute.html#impute)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e8f254-0bd9-4569-902d-1b4f343d4fad",
   "metadata": {},
   "source": [
    "##   <span style=\"color:blue\">Generación de características polinómicas</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a5101c-88d6-482b-8e05-9605465d7424",
   "metadata": {},
   "source": [
    "A menudo es útil agregar complejidad a un modelo al considerar características no lineales de los datos de entrada. Mostramos dos posibilidades que se basan en polinomios: la primera utiliza polinomios puros, la segunda utiliza splines, es decir, polinomios por partes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a162f44-1510-4f07-985b-3bf1496e911c",
   "metadata": {},
   "source": [
    "###   <span style=\"color:blue\">Características polinómicas</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f476edce-0936-4ba0-a3d5-34675ee6f522",
   "metadata": {},
   "source": [
    "Un método simple y común de usar es el de características polinómicas, que puede obtener términos de alto orden e interacción entre características. Esto se implementa en [PolynomialFeatures](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html#sklearn.preprocessing.PolynomialFeatures):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09efc7b6-b062-431a-8677-5e2d64d41e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [2, 3],\n",
       "       [4, 5]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "X = np.arange(6).reshape(3, 2)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e84966b5-e48e-4baa-9c27-3a891e076c3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  1.,  0.,  0.,  1.],\n",
       "       [ 1.,  2.,  3.,  4.,  6.,  9.],\n",
       "       [ 1.,  4.,  5., 16., 20., 25.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly = PolynomialFeatures(2)\n",
    "poly.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f54fce-4188-48cf-9f99-7ca47bb7b872",
   "metadata": {},
   "source": [
    "Las características de X han sido transformadas de $(X_1, X_2)$ a $(1, X_1, X_2, X_1^2, X_1X_2, X_2^2)$.\n",
    "\n",
    "En algunos casos, solo se requieren términos de interacción entre las características, y esto se puede lograr configurando interaction_only=True:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e0e18b5-3156-4815-a747-4bd4b55481c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 2],\n",
       "       [3, 4, 5],\n",
       "       [6, 7, 8]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.arange(9).reshape(3, 3)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06567572-6a5a-474a-ab73-f7c6ade21501",
   "metadata": {},
   "source": [
    "poly = PolynomialFeatures(degree=3, interaction_only=True)\n",
    "poly.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59694037-4f83-459e-8986-65c5917588a3",
   "metadata": {},
   "source": [
    "Las características de X han sido transformadas de $(X_1, X_2, X_3)$ a $(X_1, X_2, X_3)$.\n",
    "\n",
    "Ten en cuenta que las características polinómicas se utilizan implícitamente en los métodos de kernel (por ejemplo, [SVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC), [KernelPCA](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.KernelPCA.html#sklearn.decomposition.KernelPCA)) al utilizar funciones de kernel polinómicas.\n",
    "\n",
    "Consulta la [interpolación polinómica y de spline](https://scikit-learn.org/stable/auto_examples/linear_model/plot_polynomial_interpolation.html#sphx-glr-auto-examples-linear-model-plot-polynomial-interpolation-py) para la regresión Ridge utilizando características polinómicas creadas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16ac768-5090-4b13-82d6-ec7ac4372d65",
   "metadata": {},
   "source": [
    "###   <span style=\"color:blue\">Transformador Spline</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3b856f-9f1a-4f6a-b5b1-3f21ab70b34f",
   "metadata": {},
   "source": [
    "Otra forma de agregar términos no lineales en lugar de polinomios puros de características es generar funciones de base de spline para cada característica con el [SplineTransformer](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.SplineTransformer.html#sklearn.preprocessing.SplineTransformer). Los splines son polinomios por partes, parametrizados por su grado polinómico y las posiciones de los nudos. El SplineTransformer implementa una base de spline B, consulte las referencias a continuación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceddd863-b4e3-434b-8142-45e1c486445b",
   "metadata": {},
   "source": [
    "#### Nota\n",
    "\n",
    "El [SplineTransformer](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.SplineTransformer.html#sklearn.preprocessing.SplineTransformer) trata cada característica por separado, es decir, no proporcionará términos de interacción."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c16fb7-b781-4757-b404-ccabda1c5e16",
   "metadata": {},
   "source": [
    "Algunas de las ventajas de los splines sobre los polinomios son:\n",
    "\n",
    "- Los B-splines son muy flexibles y robustos si se mantiene un grado bajo fijo, generalmente 3, y se adapta de manera parsimoniosa el número de nudos. Los polinomios requerirían un grado más alto, lo que nos lleva al siguiente punto.\n",
    "\n",
    "- Los B-splines no tienen un comportamiento oscilatorio en los límites como ocurre con los polinomios (cuanto mayor es el grado, peor). Esto se conoce como el fenómeno de Runge.\n",
    "\n",
    "- Los B-splines proporcionan buenas opciones para la extrapolación más allá de los límites, es decir, más allá del rango de valores ajustados. Echa un vistazo a la opción \"extrapolation\".\n",
    "\n",
    "- Los B-splines generan una matriz de características con una estructura en bandas. Para una sola característica, cada fila contiene solo elementos no nulos de grado + 1, que ocurren de manera consecutiva y son incluso positivos. Esto resulta en una matriz con buenas propiedades numéricas, como un bajo número de condición, en marcado contraste con una matriz de polinomios, que recibe el nombre de matriz de Vandermonde. Un bajo número de condición es importante para algoritmos estables de modelos lineales.\n",
    "\n",
    "El siguiente fragmento de código muestra los splines en acción:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d1390ba-129f-4963-bc28-63407ab3ca1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [4]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import SplineTransformer\n",
    "X = np.arange(5).reshape(5, 1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5b34c9b8-dfa6-476b-aa5e-4f9126b1ba16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5  , 0.5  , 0.   , 0.   ],\n",
       "       [0.125, 0.75 , 0.125, 0.   ],\n",
       "       [0.   , 0.5  , 0.5  , 0.   ],\n",
       "       [0.   , 0.125, 0.75 , 0.125],\n",
       "       [0.   , 0.   , 0.5  , 0.5  ]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spline = SplineTransformer(degree=2, n_knots=3)\n",
    "spline.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8b267b-7771-47ea-873c-495ca70aa3d4",
   "metadata": {},
   "source": [
    "Cuando los datos en `X` están ordenados, es fácil ver la matriz en bandas resultante. Para `degree=2`, solo las tres diagonales centrales tienen valores distintos de cero. Cuanto mayor sea el grado, mayor será la superposición de los splines.\n",
    "\n",
    "Curiosamente, un `SplineTransformer` con `degree=0` es equivalente a `KBinsDiscretizer` con `encode='onehot-dense'` y `n_bins = n_knots - 1` si `knots = strategy`.\n",
    "\n",
    "**Ejemplos:**\n",
    "\n",
    "- [Interpolación Polinómica y de Splines](https://scikit-learn.org/stable/auto_examples/linear_model/plot_polynomial_interpolation.html#sphx-glr-auto-examples-linear-model-plot-polynomial-interpolation-py).\n",
    "\n",
    "- [Ingeniería de características relacionadas con el tiempo](https://scikit-learn.org/stable/auto_examples/applications/plot_cyclical_feature_engineering.html#sphx-glr-auto-examples-applications-plot-cyclical-feature-engineering-py).\n",
    "\n",
    "**Referencias:**\n",
    "\n",
    "- Eilers, P., & Marx, B. (1996). [Flexible Smoothing with B-splines and Penalties](https://projecteuclid.org/journals/statistical-science/volume-11/issue-2/Flexible-smoothing-with-B-splines-and-penalties/10.1214/ss/1038425655.full). Statist. Sci. 11 (1996), no. 2, 89–121.\n",
    "\n",
    "- Perperoglou, A., Sauerbrei, W., Abrahamowicz, M. et al. [A review of spline function procedures in R](https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/s12874-019-0666-3). BMC Med Res Methodol 19, 46 (2019).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2057740-bc11-4a7d-b623-576b42d2e252",
   "metadata": {},
   "source": [
    "###   <span style=\"color:blue\">Transformadores personalizados</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5848a48-5741-4bb2-817c-79c316afb2bf",
   "metadata": {},
   "source": [
    "A menudo, querrás convertir una función Python existente en un transformador para ayudar en la limpieza o procesamiento de datos. Puedes implementar un transformador a partir de una función arbitraria con [FunctionTransformer](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.FunctionTransformer.html#sklearn.preprocessing.FunctionTransformer). Por ejemplo, para construir un transformador que aplique una transformación logarítmica en un pipeline, puedes hacer lo siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f4fee53-509c-4c73-9cd3-1b99796958e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.69314718],\n",
       "       [1.09861229, 1.38629436]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "transformer = FunctionTransformer(np.log1p, validate=True)\n",
    "X = np.array([[0, 1], [2, 3]])\n",
    "# Since FunctionTransformer is no-op during fit, we can call transform directly\n",
    "transformer.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe5c8c8-fc38-48e1-adfa-b9dedb36e6c9",
   "metadata": {},
   "source": [
    "Puedes asegurarte de que func e inverse_func sean el uno inverso del otro configurando check_inverse=True y llamando a fit antes de transformar. Ten en cuenta que se genera una advertencia y se puede convertir en un error con un filtro de advertencias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ab8b83d-4baa-4b81-8abf-5e3b81850261",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"error\", message=\".*check_inverse*.\",\n",
    "                        category=UserWarning, append=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af17465e-3610-4ec8-960a-8ee563279580",
   "metadata": {},
   "source": [
    "Para obtener un ejemplo de código completo que demuestre cómo utilizar un FunctionTransformer para extraer características de datos de texto, consulta [Column Transformer with Heterogeneous Data Sources](https://scikit-learn.org/stable/auto_examples/compose/plot_column_transformer.html#sphx-glr-auto-examples-compose-plot-column-transformer-py) and [Time-related feature engineering](https://scikit-learn.org/stable/auto_examples/applications/plot_cyclical_feature_engineering.html#sphx-glr-auto-examples-applications-plot-cyclical-feature-engineering-py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9659b00-063a-4266-83ca-c4abbb0f1103",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
